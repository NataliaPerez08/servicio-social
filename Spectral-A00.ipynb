{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12359,
     "status": "ok",
     "timestamp": 1696356980755,
     "user": {
      "displayName": "Natalia Abigail Pérez Romero",
      "userId": "02764911894153294828"
     },
     "user_tz": 360
    },
    "id": "GDhExolHHwYp",
    "outputId": "a2aecca7-60f4-4f9d-8c4b-6db4cf8750c6"
   },
   "outputs": [],
   "source": [
    "#print(\"Instalar librerias necesarias\")\n",
    "#!pip install spectral specdal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IryL04Uh9XUk"
   },
   "source": [
    "# Espectros\n",
    "Los que tienen nombre spectrum son los espectros de la tabla con el pigmento. Los que comienzan con A00 son de las cerámicas y estándares. Los que tienen extensión asd, son los que da el sistema, los que tienen extensión .txt son los ya procesados y los hr.txt son los procesados que ya se les ajustó la curva. Finalmente los espectros 12,13,14, 15 y 130 son cerámicas. Y los otros son los estándares 131-blanco, 132-Amarillo, 133-Rojo, 134-Azul y 135-Verde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lo3Ib63TgQrV"
   },
   "source": [
    "# Spectral Algorithms\n",
    "\n",
    "Spectral Angle Mapper (SAM) is a physically-based spectral classification that uses an n-D angle to match pixels to reference spectra. The algorithm determines the spectral similarity between two spectra by calculating the angle between the spectra and treating them as vectors in a space with dimensionality equal to the number of bands. This technique, when used on calibrated reflectance data, is relatively insensitive to illumination and albedo effects. Endmember spectra can be directly extracted directly from an image as region of interest (ROI) mean spectra. SAM compares the angle between the endmember spectrum vector and each pixel vector in n-D space. Smaller angles represent closer matches to the reference spectrum. Pixels further away than the specified maximum angle threshold in radians are not classified.\n",
    "\n",
    "SAM classification assumes reflectance data. However, if you use radiance data, the error is generally not significant because the origin is still near zero.\n",
    "\n",
    "Reference: Kruse, F. A., A. B. Lefkoff, J. B. Boardman, K. B. Heidebrecht, A. T. Shapiro, P. J. Barloon, and A. F. H. Goetz. \"The Spectral Image Processing System (SIPS) - Interactive Visualization and Analysis of Imaging spectrometer Data.\" Remote Sensing of Environment 44 (1993): 145-163.\n",
    "\n",
    "\n",
    "SpecDAL Reference\n",
    "\n",
    "https://specdal.readthedocs.io/en/latest/\n",
    "\n",
    "https://specdal.readthedocs.io/en/latest/api.html\n",
    "\n",
    "https://pyspectrum.readthedocs.io/en/latest/ref_others.html?highlight=derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "executionInfo": {
     "elapsed": 3011,
     "status": "ok",
     "timestamp": 1696356983758,
     "user": {
      "displayName": "Natalia Abigail Pérez Romero",
      "userId": "02764911894153294828"
     },
     "user_tz": 360
    },
    "id": "Yd8Q_1uWgMM1",
    "outputId": "a3d7ecca-a207-460f-9531-e56ccf9cd92c"
   },
   "outputs": [],
   "source": [
    "import specdal\n",
    "# Pigmento\n",
    "a00012 = 'Espectros FORS/A00012.asd'\n",
    "\n",
    "s = specdal.Spectrum(filepath=a00012)\n",
    "data_c=s.measurement\n",
    "s.plot()\n",
    "\n",
    "s.derivative()\n",
    "s.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 1506,
     "status": "ok",
     "timestamp": 1696356985257,
     "user": {
      "displayName": "Natalia Abigail Pérez Romero",
      "userId": "02764911894153294828"
     },
     "user_tz": 360
    },
    "id": "SDRJltP6nUni",
    "outputId": "ea5205d9-ef77-4e35-8dd8-b3430cbc8ebc"
   },
   "outputs": [],
   "source": [
    "# estándares 131-blanco, 132-Amarillo, 133-Rojo, 134-Azul y 135-Verde.\n",
    "\n",
    "# Estandar blanco\n",
    "a00131 = 'Espectros FORS/A00131.asd'\n",
    "a131 = specdal.Spectrum(filepath=a00131)\n",
    "a131.plot()\n",
    "data_blanco = a131.measurement\n",
    "\n",
    "\n",
    "# Estandar amarillo\n",
    "a00132 = 'Espectros FORS/A00132.asd'\n",
    "a132 = specdal.Spectrum(filepath=a00132)\n",
    "a132.plot()\n",
    "data_amarillo = a132.measurement\n",
    "\n",
    "\n",
    "# Estandar rojo\n",
    "a00133 = 'Espectros FORS/A00133.asd'\n",
    "a133 = specdal.Spectrum(filepath=a00133)\n",
    "a133.plot()\n",
    "data_rojo = a133.measurement\n",
    "\n",
    "# Estandar azul\n",
    "a00134 = 'Espectros FORS/A00134.asd'\n",
    "a134 = specdal.Spectrum(filepath=a00134)\n",
    "a134.plot()\n",
    "data_azul = a134.measurement\n",
    "\n",
    "# Estandar verde\n",
    "a00135 = 'Espectros FORS/A00135.asd'\n",
    "a135 = specdal.Spectrum(filepath=a00135)\n",
    "a135.plot()\n",
    "data_verde = a135.measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOuQD1v_tGvC"
   },
   "source": [
    "# K-Nearest Neighbors Algorithm\n",
    "\n",
    "The k-nearest neighbors algorithm, also known as KNN or k-NN, is a non-parametric, supervised learning classifier, which uses proximity to make classifications or predictions about the grouping of an individual data point. While it can be used for either regression or classification problems, it is typically used as a classification algorithm, working off the assumption that similar points can be found near one another.\n",
    "\n",
    "https://www.ibm.com/topics/knn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxzSQnrjuEPB"
   },
   "source": [
    "The KNN Algorithm\n",
    "1. Load the data\n",
    "2. Initialize K to your chosen number of neighbors\n",
    "3. For each example in the data\n",
    "  3. 1 Calculate the distance between the query example and the current example from the data.\n",
    "  3. 2 Add the distance and the index of the example to an ordered collection\n",
    "\n",
    "4. Sort the ordered collection of distances and indices from smallest to largest (in ascending order) by the distances\n",
    "\n",
    "5. Pick the first K entries from the sorted collection\n",
    "\n",
    "6. Get the labels of the selected K entries\n",
    "\n",
    "7. If regression, return the mean of the K labels\n",
    "\n",
    "8. If classification, return the mode of the K labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kzkw6XphplS6"
   },
   "source": [
    "# Ejemplo de NearestNeighbors\n",
    "\n",
    "Docs: https://scikit-learn.org/stable/modules/neighbors.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1402,
     "status": "ok",
     "timestamp": 1696356986651,
     "user": {
      "displayName": "Natalia Abigail Pérez Romero",
      "userId": "02764911894153294828"
     },
     "user_tz": 360
    },
    "id": "w91DnRQPpuMr"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(X)\n",
    "distances, indices = nbrs.kneighbors(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 451,
     "status": "ok",
     "timestamp": 1696356987098,
     "user": {
      "displayName": "Natalia Abigail Pérez Romero",
      "userId": "02764911894153294828"
     },
     "user_tz": 360
    },
    "id": "mbgiBGvhsYVM",
    "outputId": "e284bc36-ff0c-4ad3-d697-a934a974d9f3"
   },
   "outputs": [],
   "source": [
    "X = np.array([data_c,data_rojo])#,data_a])\n",
    "nbrs = NearestNeighbors(n_neighbors=2).fit(X)\n",
    "distances, indices = nbrs.kneighbors(X)\n",
    "print(distances)\n",
    "nbrs.kneighbors_graph(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1696356987098,
     "user": {
      "displayName": "Natalia Abigail Pérez Romero",
      "userId": "02764911894153294828"
     },
     "user_tz": 360
    },
    "id": "C1ECfuFkBs0F",
    "outputId": "49b586b3-45ef-4e73-95fa-dc449d4ff0c0"
   },
   "outputs": [],
   "source": [
    "X[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVOCcLeou4f_"
   },
   "source": [
    "MultiClass Classification Using K-Nearest Neighbours\n",
    "\n",
    "https://towardsdatascience.com/multiclass-classification-using-k-nearest-neighbours-ca5281a9ef76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mYRged-3vXy"
   },
   "source": [
    "\n",
    "# Spectral–Spatial HyperspectralImage Classification With K-Nearest Neighbor and Guided Filter\n",
    "https://ieeexplore.ieee.org/document/8327484\n",
    "\n",
    "KNN algorithm is a non-parametric method widely used for classification in pattern recognition. The main principle of KNN is that category of a data point is determined according to the classification of the nearest K neighbors. Take\n",
    "$$T=\\{(x_1,y_1),(x_2,y_2),⋯,(x_N,y_N)\\}$$\n",
    "as a training set, and $N$ is the number of training entities. Here $x_i \\in R^d$ denotes the feature vectors, and $y_i \\in Y=\\{c_1,c_2,...,c_m\\}$ denotes the labels of classification, $i=1,2,\\dots,N$. Given an input $x$, we can obtain the k-nearest neighbors $N_k(x)$ by computing the distance with the traing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFcUHBTV-9YI"
   },
   "source": [
    "En nuestro caso: Tomemos $\\texttt{data\\_r}$ el espectro del éstandar rojo. El cual tiene $\\texttt{features: wavelength, reflectance}$\n",
    "\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.ndarray.fill.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3--OJ5YbtjMN"
   },
   "source": [
    "fit(X, y)\n",
    "Fit the k-nearest neighbors classifier from the training dataset.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "X **{array-like, sparse matrix}** of shape (n_samples, n_features) or (n_samples, n_samples) if metric=’precomputed’\n",
    "Training data.\n",
    "\n",
    "\n",
    "y **{array-like, sparse matrix}** of shape (n_samples,) or (n_samples, n_outputs)\n",
    "Target values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3qESpSQu11t"
   },
   "source": [
    "Mi implentación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5459,
     "status": "ok",
     "timestamp": 1696356992552,
     "user": {
      "displayName": "Natalia Abigail Pérez Romero",
      "userId": "02764911894153294828"
     },
     "user_tz": 360
    },
    "id": "iZKf-06t-vYZ",
    "outputId": "576dd46c-dcfe-4ab2-d43c-c76ecfc0ffbc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Crear dataFrame apropiado para el modelo\n",
    "# Tiene la forma wavelength, reflectance, class\n",
    "\n",
    "# estándares 131-blanco, 132-Amarillo, 133-Rojo, 134-Azul y 135-Verde.\n",
    "reflectance = np.array(data_blanco)\n",
    "size = len(reflectance) #size=2151\n",
    "indexes=data_amarillo.index\n",
    "\n",
    "\n",
    "tmp_class = ['blanco' for i in range(size)]\n",
    "reflectance = np.array(data_blanco)\n",
    "array_b = np.stack([indexes,reflectance,tmp_class], axis=1)\n",
    "\n",
    "tmp_class = ['amarillo' for i in range(size)]\n",
    "reflectance = np.array(data_amarillo)\n",
    "array_a = np.stack([indexes,reflectance,tmp_class], axis=1)\n",
    "\n",
    "tmp_class = ['rojo' for i in range(size)]\n",
    "reflectance = np.array(data_rojo)\n",
    "array_r = np.stack([indexes,reflectance,tmp_class], axis=1)\n",
    "\n",
    "tmp_class = ['azul' for i in range(size)]\n",
    "\n",
    "reflectance = np.array(data_azul)\n",
    "array_z = np.stack([indexes,reflectance,tmp_class], axis=1)\n",
    "\n",
    "tmp_class = ['verde' for i in range(size)]\n",
    "reflectance = np.array(data_verde)\n",
    "array_v = np.stack([indexes,reflectance,tmp_class], axis=1)\n",
    "\n",
    "# Concatenate Target values\n",
    "y = np.concatenate((array_b,array_a,array_r,array_z,array_v))\n",
    "#print(\"Y=\")\n",
    "#print(y)\n",
    "\n",
    "# X Training data\n",
    "X_b = np.array(data_blanco)\n",
    "X_a = np.array(data_amarillo)\n",
    "X_r = np.array(data_rojo)\n",
    "X_z = np.array(data_azul)\n",
    "X_v = np.array(data_verde)\n",
    "\n",
    "t = [2 for i in range(len(reflectance))]\n",
    "array_X_b = np.stack([X_b,t], axis=1)\n",
    "array_X_a = np.stack([X_a,t], axis=1)\n",
    "array_X_r = np.stack([X_r,t], axis=1)\n",
    "array_X_z = np.stack([X_z,t], axis=1)\n",
    "array_X_v = np.stack([X_v,t], axis=1)\n",
    "array_X = np.concatenate((array_X_b,array_X_a,array_X_r,array_X_z,array_X_v))\n",
    "print(array_X)\n",
    "\n",
    "# = data_a  # y Target values\n",
    "classes = np.array(['blanco','amarillo','rojo','azul','verde'])\n",
    "neigh = KNeighborsClassifier()\n",
    "neigh.classes_ = classes\n",
    "neigh.n_features_in_=2\n",
    "neigh.n_jobs=3\n",
    "\n",
    "neigh.fit(array_X,y)\n",
    "\n",
    "\n",
    "X = np.array(data_amarillo)\n",
    "t = [2 for i in range(len(reflectance))]\n",
    "array_X = np.stack([X,t], axis=1)\n",
    "print(\"X=\")\n",
    "array_X = np.concatenate((array_X,array_X,array_X,array_X,array_X))\n",
    "print(array_X)\n",
    "\n",
    "prediccion=neigh.predict(array_X)\n",
    "print(\"Prediccion=\")\n",
    "print(prediccion)\n",
    "frec = {'blanco':0,'amarillo':0,'rojo':0,'azul':0,'verde':0}\n",
    "for ren in prediccion:\n",
    "  elem=ren[2]\n",
    "  if elem in frec:\n",
    "    frec[elem] +=1\n",
    "\n",
    "print(frec)\n",
    "\n",
    "print(\"Probabilidad por clase: \")\n",
    "neigh.predict_proba(array_X)[2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhIFhjlt719i"
   },
   "source": [
    "Ahora que puede clasificarse a si mismo, podemos probar con una ceramica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8390,
     "status": "ok",
     "timestamp": 1696357000936,
     "user": {
      "displayName": "Natalia Abigail Pérez Romero",
      "userId": "02764911894153294828"
     },
     "user_tz": 360
    },
    "id": "N3rtNlyq8HL6",
    "outputId": "235ac751-07c9-4187-f563-f05e9864009b"
   },
   "outputs": [],
   "source": [
    "X = np.array(data_c)\n",
    "t = [2 for i in range(len(reflectance))]\n",
    "array_X = np.stack([X,t], axis=1)\n",
    "print(\"X=\")\n",
    "array_X = np.concatenate((array_X,array_X,array_X,array_X,array_X))\n",
    "print(array_X)\n",
    "\n",
    "prediccion=neigh.predict(array_X)\n",
    "print(\"Prediccion=\")\n",
    "print(prediccion)\n",
    "frec = {'blanco':0,'amarillo':0,'rojo':0,'azul':0,'verde':0}\n",
    "for ren in prediccion:\n",
    "  elem=ren[2]\n",
    "  if elem in frec:\n",
    "    frec[elem] +=1\n",
    "\n",
    "print(frec)\n",
    "\n",
    "print(\"Probabilidad por clase: \")\n",
    "neigh.predict_proba(array_X)[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7R-5zpe_U3D"
   },
   "source": [
    "# Seccionar espectro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1696357000937,
     "user": {
      "displayName": "Natalia Abigail Pérez Romero",
      "userId": "02764911894153294828"
     },
     "user_tz": 360
    },
    "id": "e2jq5Hm5pSJ9",
    "outputId": "134c413c-2517-4c80-eece-7445756a4ee9"
   },
   "outputs": [],
   "source": [
    "s=pd.cut(data_amarillo, 20)\n",
    "print(s.values)\n",
    "s.__array__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBzus58dMLt-"
   },
   "source": [
    "# Bayes ingenuo\n",
    "\n",
    "Naive Bayes classifier calculates the probability of an event in the following steps:\n",
    "\n",
    "Step 1: Calculate the prior probability for given class labels\n",
    "\n",
    "Step 2: Find Likelihood probability with each attribute for each class\n",
    "\n",
    "Step 3: Put these value in Bayes Formula and calculate posterior probability.\n",
    "\n",
    "Step 4: See which class has a higher probability, given the input belongs to the higher probability class.\n",
    "\n",
    "https://www.datacamp.com/tutorial/naive-bayes-scikit-learn\n",
    "\n",
    "X: array-like of shape (n_samples, n_features)\n",
    "Training vectors, where n_samples is the number of samples and n_features is the number of features.\n",
    "\n",
    "y: array-like of shape (n_samples,)\n",
    "Target values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNEu_ttZ08ll"
   },
   "source": [
    "# Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 171,
     "status": "ok",
     "timestamp": 1696361197366,
     "user": {
      "displayName": "Natalia Abigail Pérez Romero",
      "userId": "02764911894153294828"
     },
     "user_tz": 360
    },
    "id": "0wQJs5W8MZMb",
    "outputId": "3d04a025-b394-4d12-f4af-980bf304d72b"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_breast_cancer()\n",
    "label_names = data['target_names']\n",
    "labels = data['target']\n",
    "feature_names = data['feature_names']\n",
    "features = data['data']\n",
    "print(label_names)\n",
    "print(labels[0])\n",
    "print(feature_names[0])\n",
    "print(features[0].size)\n",
    "train, test, train_labels, test_labels = train_test_split(\n",
    "   features,labels,test_size = 0.40, random_state = 42\n",
    ")\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "GNBclf = GaussianNB()\n",
    "model = GNBclf.fit(train, train_labels)\n",
    "print(GNBclf.classes_)\n",
    "#preds = GNBclf.predict(test)\n",
    "#print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkYCS2VRW5EY"
   },
   "source": [
    "----\n",
    "# Aplicación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "executionInfo": {
     "elapsed": 180,
     "status": "ok",
     "timestamp": 1696362803289,
     "user": {
      "displayName": "Natalia Abigail Pérez Romero",
      "userId": "02764911894153294828"
     },
     "user_tz": 360
    },
    "id": "0WLi7wmaW7YR",
    "outputId": "45c1d3eb-5150-48fa-b245-5245764ed4f7",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "# data = {[X_b,X_a,...], [blanco,rojo],\n",
    "#label_names = data['target_names']\n",
    "label_names =  ['blanco','amarillo','rojo','azul','verde']\n",
    "\n",
    "#labels = data['target']\n",
    "labels = [0,1,2,3,4]\n",
    "\n",
    "#feature_names = data['feature_names']\n",
    "feature_names = ['wavelength','reflectance']\n",
    "\n",
    "#features = data['data']\n",
    "features = np.array((X_b,X_a,X_r,X_z,X_v))\n",
    "print(features)\n",
    "\n",
    "#print(label_names)\n",
    "#print(labels[0])\n",
    "#print(feature_names[1])\n",
    "#print(features[0])\n",
    "train, test, train_labels, test_labels = train_test_split(\n",
    "   features,labels,test_size = 0.010, random_state = 22\n",
    ")\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "GNBclf = GaussianNB()\n",
    "print(train_labels)\n",
    "print(train.shape)\n",
    "\n",
    "model = GNBclf.fit(train, train_labels)\n",
    "print(model.classes_)\n",
    "test=[data_blanco,data_amarillo,data_rojo,data_azul,data_verde]\n",
    "preds = GNBclf.predict(test)\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zyc74wIkOktw"
   },
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 244,
     "status": "aborted",
     "timestamp": 1696357001920,
     "user": {
      "displayName": "Natalia Abigail Pérez Romero",
      "userId": "02764911894153294828"
     },
     "user_tz": 360
    },
    "id": "vV0oJ_lsOoUH"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(train, train_labels)\n",
    "reg.score(train, train_labels)\n",
    "pb = reg.predict(np.array([data_blanco,data_amarillo,data_rojo,data_azul,data_verde]))\n",
    "print(\"pb[0] =\",round(pb[0],2))\n",
    "print(\"pb[1] =\",round(pb[1],2))\n",
    "print(\"pb[2] =\",round(pb[2],2))\n",
    "print(\"pb[3] =\",round(pb[3],2))\n",
    "print(\"pb[4] =\",round(pb[4],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yleci7pUDwmd"
   },
   "source": [
    "#ToDo\n",
    "Bayes ingenueo con colores y pigmentos.\n",
    "\n",
    "\n",
    "Aplicar k.vecinos en pigmentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "clf = LogisticRegression(penalty='l2',solver='lbfgs', max_iter=400)\n",
    "#make_pipeline(StandardScaler(), LogisticRegression())\n",
    "clf.fit(train, train_labels)\n",
    "clf.score(train, train_labels)\n",
    "clf.predict_proba(np.array([data_blanco,data_amarillo,data_rojo,data_azul,data_verde]))\n",
    "clf.predict(np.array([data_blanco,data_amarillo,data_rojo,data_azul,data_verde]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import Perceptron\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(train, train_labels)\n",
    "Perceptron()\n",
    "clf.score(train, train_labels)\n",
    "clf.predict(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSy5o2qqDuIg"
   },
   "source": [
    "# TODO -despues\n",
    "Trabajar anterior con redes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "\n",
    "X = torch.rand(1, 28, 28, device=device)\n",
    "print(X)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación\n",
    "https://www.learnpytorch.io/02_pytorch_classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmp_c = [0 for i in range(size)]\n",
    "array_X_b = np.stack([indexes,X_b,tmp_c], axis=1)\n",
    "\n",
    "tmp_c = [1 for i in range(size)]\n",
    "array_X_a = np.stack([indexes,X_a,tmp_c], axis=1)\n",
    "\n",
    "tmp_c = [2 for i in range(size)]\n",
    "array_X_r = np.stack([indexes,X_r,tmp_c], axis=1)\n",
    "\n",
    "tmp_c = [3 for i in range(size)]\n",
    "array_X_z = np.stack([indexes,X_z,tmp_c], axis=1)\n",
    "\n",
    "tmp_c = [4 for i in range(size)]\n",
    "array_X_v = np.stack([indexes,X_v,tmp_c], axis=1)\n",
    "\n",
    "x_np = np.array((array_X_b,array_X_a,array_X_r,array_X_z,array_X_v))\n",
    "\n",
    "xNP = torch.from_numpy(x_np)\n",
    "print(xNP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Estandar(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.linear_relu_stack = nn.Sequential(\n",
    "        self.fc=nn.Linear(2151*2, 1),\n",
    "        #nn.ReLU(),\n",
    "        #nn.Linear(512, 12),\n",
    "        #nn.ReLU(),\n",
    "           #nn.Linear(512, 10),\n",
    "        #)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.fc(x)\n",
    "        return x\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "model = Estandar()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "print(model.parameters)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64  # Adjust as needed\n",
    "dataloader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs=100):\n",
    "    for batch in dataloader:\n",
    "        inputs = batch.float()  # Convert to float tensor if needed\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, test)  # Define targets depending on your task\n",
    "        #optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        #optimizer.step()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOxZCYXX4gOR1WgMdDuyEbu",
   "mount_file_id": "12H2YPKYbwk7zDNk72ui6ZMwwYqb2Etsx",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
